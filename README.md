# ğŸ¼ BabyWhisper - AI-Powered Baby Cry Classification System

**Revolutionary AI system that combines advanced audio processing with contextual intelligence to help parents understand their babies better.**

BabyWhisper doesn't just classify baby criesâ€”it provides intelligent, context-aware insights that take into account each baby's unique patterns, feeding schedules, sleep cycles, and developmental stage.

## âœ¨ Key Features

- **ğŸ¯ Real Baby Cry Analysis**: Trained on 457 real baby cry recordings from the Donate-a-Cry dataset
- **ğŸ§  Multi-Model Intelligence**: Ensemble of Random Forest, SVM, and Neural Network classifiers
- **ğŸµ 293 Audio Features**: Advanced signal processing extracts comprehensive acoustic patterns
- **ğŸ¯ 83.7% Accuracy**: Realistic performance on real-world baby cry classification  
- **ğŸ§ Context-Aware Intelligence**: Considers feeding times, sleep patterns, and baby's schedule
- **ğŸ“ˆ Continuous Learning**: Adapts predictions based on parent feedback
- **âš¡ Real-Time Processing**: Fast classification for immediate insights
- **ğŸŒ Web Dashboard**: Beautiful React interface for easy interaction
- **ğŸ“Š Advanced Analytics**: Track patterns and generate insights over time

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Audio Input   â”‚â”€â”€â”€â–¶â”‚ Feature Extractionâ”‚â”€â”€â”€â–¶â”‚   Ensemble Models   â”‚
â”‚  (Baby Cry)     â”‚    â”‚  (293 features)   â”‚    â”‚  RF + SVM + MLP     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚ Smart Insights  â”‚â—€â”€â”€â”€â”‚ Context Layer    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ & Explanations  â”‚    â”‚ (Baby Profile +  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  Care History)   â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ—ï¸ Architecture & Design Decisions

### **System Overview**

BabyWhisper employs a **modular, scalable architecture** designed for real-world baby care applications. The system combines **advanced audio processing**, **ensemble machine learning**, and **context-aware intelligence** to deliver accurate, personalized insights.

### **Core Design Principles**

#### **1. Real-World Data First**
- **Decision**: Train exclusively on real baby cry recordings
- **Rationale**: Synthetic data doesn't capture authentic cry patterns
- **Implementation**: 457 recordings from Donate-a-Cry corpus
- **Result**: 83.7% accuracy on genuine baby cries

#### **2. Ensemble Learning Strategy**
- **Decision**: Combine multiple ML models instead of single model
- **Rationale**: Different models excel at different audio patterns
- **Implementation**: Random Forest + SVM + Multi-layer Perceptron
- **Result**: Robust predictions across diverse cry types

#### **3. Context-Aware Intelligence**
- **Decision**: Integrate baby-specific context into predictions
- **Rationale**: Same cry can mean different things based on timing/schedule
- **Implementation**: Baby profiles with feeding/sleep/diaper history
- **Result**: Personalized insights beyond basic classification

#### **4. Modular Architecture**
- **Decision**: Separate concerns into distinct modules
- **Rationale**: Maintainability, testability, and extensibility
- **Implementation**: Audio processing, ML models, context management
- **Result**: Easy to enhance and debug individual components

### **Technical Architecture Deep Dive**

#### **Audio Processing Pipeline**
```
Raw Audio â†’ Preprocessing â†’ Feature Extraction â†’ Model Input
    â†“              â†“              â†“              â†“
  WAV/MP3    Noise Removal   293 Features   Ensemble
  Input      Normalization   (MFCC, Spec,   Prediction
                            Temporal, F0)
```

#### **Machine Learning Stack**
- **Feature Engineering**: 293 audio characteristics per sample
- **Model Ensemble**: 
  - Random Forest (79.3% test accuracy)
  - Support Vector Machine (83.7% test accuracy)  
  - Multi-layer Perceptron (79.3% test accuracy)
  - Ensemble Voting (83.7% validation accuracy)
- **Training Data**: 457 real baby cry recordings
- **Validation**: Cross-validation with real-world test sets

#### **Context Intelligence System**
- **Baby Profiles**: Individual characteristics and patterns
- **Care History**: Feeding, sleep, diaper change tracking
- **Time Awareness**: Time-of-day and schedule-based adjustments
- **Feedback Learning**: Continuous improvement from user input

#### **Web Application Architecture**
```
Frontend (React) â†â†’ Backend (Flask) â†â†’ AI Engine (Python)
     â†“                    â†“                    â†“
  User Interface    REST API Endpoints   ML Models
  Real-time Audio   Baby Management      Context Engine
  Analytics Dash    File Upload          Audio Processing
```

### **Key Design Decisions Explained**

#### **Why 293 Audio Features?**
- **Optimized Coverage**: MFCC, mel-spectrograms, temporal, and F0 features
- **Pattern Recognition**: Captures both frequency and time-domain patterns
- **Robustness**: Multiple feature types handle different cry characteristics
- **Validation**: Feature importance analysis guides selection
- **Performance**: Balanced accuracy vs. computational efficiency

#### **Why Ensemble Over Single Model?**
- **Diversity**: Each model specializes in different audio patterns
- **Reliability**: Reduces overfitting and improves generalization
- **Performance**: Better accuracy than individual models
- **Flexibility**: Easy to add/remove models as needed
- **Real Results**: SVM (83.7%), RF (79.3%), MLP (79.3%) test accuracies

#### **Why Context-Aware Predictions?**
- **Real-World Accuracy**: Same cry means different things at different times
- **Personalization**: Each baby has unique patterns and needs
- **Parent Trust**: More relevant and actionable insights
- **Learning**: System improves with usage and feedback

#### **Why Web Application?**
- **Accessibility**: Works on any device with a browser
- **Real-time**: Immediate analysis and feedback
- **Scalability**: Can handle multiple users and babies
- **Integration**: Easy to add features and connect to other systems

### **Recent Improvements & Fixes**

#### **Label Encoding Fix (Latest)**
- **Issue**: Test accuracies showing 0.000 due to label encoding mismatch
- **Solution**: Proper conversion between encoded and original labels
- **Result**: All models now show realistic test accuracies (79.3% - 83.7%)

#### **Feature Optimization**
- **Removed**: Chroma and spectral features for better performance
- **Kept**: MFCC, mel-spectrograms, temporal, and F0 features
- **Result**: 293 optimized features with maintained accuracy

#### **Ensemble Stability**
- **Reverted**: From experimental CNN hybrid to proven ensemble
- **Maintained**: Random Forest + SVM + MLP combination
- **Result**: Stable 83.7% validation accuracy

### **Performance Considerations**

#### **Real-Time Processing**
- **Audio Duration**: Optimized for 3-second cry samples
- **Feature Extraction**: Efficient 293-feature computation
- **Model Inference**: Fast ensemble prediction
- **Response Time**: <2 seconds end-to-end

#### **Scalability Design**
- **Modular Components**: Easy to scale individual parts
- **Stateless API**: Horizontal scaling capability
- **Model Caching**: Pre-loaded models for fast inference
- **Database Ready**: Architecture supports persistent storage

#### **Reliability Features**
- **Error Handling**: Graceful degradation on model failures
- **Input Validation**: Robust audio file processing
- **Fallback Mechanisms**: Multiple model voting system
- **Monitoring**: Comprehensive logging and error tracking

### **Future Architecture Considerations**

#### **Mobile Integration**
- **React Native**: Cross-platform mobile app
- **Offline Capability**: Local model inference
- **Push Notifications**: Real-time alerts and insights

#### **IoT Connectivity**
- **Smart Monitors**: Direct integration with baby monitors
- **Sensor Fusion**: Combine audio with movement/sleep data
- **Edge Computing**: Local processing for privacy

#### **Advanced ML Pipeline**
- **Transformer Models**: Attention-based audio processing
- **Transfer Learning**: Pre-trained models for better accuracy
- **Active Learning**: Continuous model improvement

## ğŸ“ Project Structure

```
BabyWhisper/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ audio_processing/          # Audio feature extraction & preprocessing
â”‚   â”‚   â”œâ”€â”€ feature_extractor.py   # 293 audio features extraction
â”‚   â”‚   â””â”€â”€ preprocessor.py        # Audio cleaning & normalization
â”‚   â”œâ”€â”€ models/                    # Machine learning components
â”‚   â”‚   â”œâ”€â”€ classifier.py          # Ensemble models (RF+SVM+MLP)
â”‚   â”‚   â””â”€â”€ model_trainer.py       # Training pipeline & evaluation
â”‚   â”œâ”€â”€ context/                   # Context intelligence system
â”‚   â”‚   â”œâ”€â”€ baby_profile.py        # Individual baby profiles & patterns
â”‚   â”‚   â””â”€â”€ context_manager.py     # Smart prediction adjustments
â”‚   â”œâ”€â”€ utils/                     # Utilities & evaluation
â”‚   â”‚   â”œâ”€â”€ data_loader.py         # Dataset management & real data loading
â”‚   â”‚   â””â”€â”€ evaluation.py          # Performance metrics & reporting
â”‚   â””â”€â”€ main.py                    # Main BabyWhisper interface
â”œâ”€â”€ web_app/                       # Web application
â”‚   â”œâ”€â”€ frontend/                  # React.js frontend
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ pages/             # Dashboard, Analytics, Baby Profiles
â”‚   â”‚   â”‚   â”œâ”€â”€ components/        # Reusable UI components
â”‚   â”‚   â”‚   â””â”€â”€ utils/             # Frontend utilities
â”‚   â”‚   â””â”€â”€ public/                # Static assets
â”‚   â””â”€â”€ backend/                   # Flask API backend
â”‚       â”œâ”€â”€ app.py                 # Main Flask application
â”‚       â””â”€â”€ routes/                # API endpoint definitions
â”œâ”€â”€ tests/                         # Comprehensive test suite
â”‚   â”œâ”€â”€ test_audio_processing.py   # Audio feature extraction tests
â”‚   â”œâ”€â”€ test_models.py             # ML model tests
â”‚   â”œâ”€â”€ test_context.py            # Context management tests
â”‚   â”œâ”€â”€ test_web_app.py            # API endpoint tests
â”‚   â”œâ”€â”€ test_integration.py        # End-to-end system tests
â”‚   â””â”€â”€ run_tests.py               # Test runner
â”œâ”€â”€ data/                          # Dataset storage
â”‚   â””â”€â”€ donateacry_corpus_cleaned_and_updated_data/  # Real baby cry dataset
â”œâ”€â”€ models/                        # Trained model storage
â”œâ”€â”€ notebooks/                     # Jupyter notebooks for development
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ .gitignore                     # Git ignore rules
â””â”€â”€ README.md                      # This file
```

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/dawofisayo/BabyWhisper.git
cd BabyWhisper

# Install Python dependencies
pip install -r requirements.txt

# Install frontend dependencies
cd web_app/frontend
npm install
cd ../..
```

### Running the Web Application

```bash
# Start the backend server
cd web_app/backend
python app.py

# In another terminal, start the frontend
cd web_app/frontend
npm start
```

The web application will be available at:
- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:5001

### Basic Usage (Python API)

```python
from src.main import BabyWhisperClassifier
from src.context import BabyProfile
from datetime import datetime, timedelta

# Initialize the system
baby_whisper = BabyWhisperClassifier()

# Create a baby profile for context-aware predictions
baby_profile = baby_whisper.create_baby_profile(
    name="Emma",
    age_months=4,
    birth_date=datetime.now() - timedelta(days=120)
)

# Update baby's current context
baby_whisper.update_baby_context(
    profile_id=baby_profile,
    feeding_time=datetime.now() - timedelta(hours=2.5),
    nap_time=datetime.now() - timedelta(hours=1.5),
    diaper_change_time=datetime.now() - timedelta(minutes=45)
)

# Classify a cry with intelligent context
result = baby_whisper.classify_cry(
    audio_path="path/to/baby_cry.wav",
    baby_profile=baby_profile
)

print(f"Prediction: {result['prediction']}")
print(f"Confidence: {result['confidence']:.2f}")
print(f"Recommendations: {result['recommendations']}")
```

## ğŸ§ª Testing

Run the comprehensive test suite:

```bash
# Run all tests
python tests/run_tests.py

# Run specific test categories
python -m pytest tests/test_audio_processing.py
python -m pytest tests/test_models.py
python -m pytest tests/test_integration.py
```

## ğŸ¯ Performance Metrics

Our AI achieves impressive results on real baby cry data:

| Model | Test Accuracy | Validation Accuracy | Precision | Recall | F1-Score |
|-------|---------------|-------------------|-----------|---------|----------|
| **Ensemble** | **83.7%** | **83.7%** | **83.2%** | **83.7%** | **83.4%** |
| SVM | 83.7% | 83.7% | 83.2% | 83.7% | 83.4% |
| MLP Neural Network | 79.3% | 80.4% | 79.2% | 79.3% | 79.2% |
| Random Forest | 79.3% | 83.7% | 79.2% | 79.3% | 79.2% |

*Trained and tested on 457 real baby cry recordings from the Donate-a-Cry dataset*

### Technical Specifications
- **Audio Features**: 293 characteristics per cry sample
- **Processing Speed**: Real-time capable (<2 seconds)
- **Model Types**: Ensemble (Random Forest + SVM + Multi-layer Perceptron)
- **Context Factors**: Feeding history, sleep patterns, age, time of day
- **Supported Audio**: WAV, MP3, FLAC formats
- **Web Interface**: React.js frontend with Flask API backend

## ğŸ§ª Development Journey

Explore the complete development process in our interactive Jupyter notebook:

```bash
jupyter notebook notebooks/demo_notebook.ipynb
```

The notebook includes:
- ğŸ”¬ **Audio feature exploration** and experimentation
- ğŸ¤– **ML model comparison** and performance testing  
- ğŸ§  **Context intelligence development** and validation
- ğŸš€ **System integration** and end-to-end testing
- ğŸ’­ **Technical insights** and lessons learned

## ğŸŒŸ What Makes BabyWhisper Special

### ğŸ¯ **Real Data Training**
Unlike other solutions that rely on synthetic or limited data, BabyWhisper is trained on **457 real baby cry recordings** from the Donate-a-Cry corpus, ensuring authentic pattern recognition.

### ğŸ§  **Context-Aware Intelligence** 
The system doesn't just classify criesâ€”it considers your baby's **feeding schedule, sleep patterns, and individual characteristics** to provide personalized insights.

### ğŸ”„ **Continuous Learning**
BabyWhisper learns from your feedback, becoming more accurate for your specific baby over time.

### ğŸ“Š **Comprehensive Analytics**
Track patterns, identify trends, and gain insights into your baby's needs and development.

## ğŸ”¬ Technical Innovation

- **Feature Engineering**: 293 sophisticated audio characteristics
- **Ensemble Learning**: Multiple ML models for robust predictions  
- **Context Integration**: Baby-specific pattern recognition
- **Real-time Processing**: Optimized for immediate insights
- **Modular Architecture**: Extensible and maintainable codebase

## ğŸ¤ Contributing

We welcome contributions! Areas for development:

1. **Real Dataset Integration**: Help us gather authentic baby cry recordings
2. **Mobile App Development**: React Native/Flutter implementation
3. **IoT Integration**: Smart baby monitor connectivity
4. **Advanced ML**: Transformer models, voice recognition
5. **Clinical Validation**: Pediatric research collaboration

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Audio processing powered by `librosa` and `soundfile`
- Machine learning with `scikit-learn` and `tensorflow`
- Special thanks to the open-source audio processing community

---

**BabyWhisper: Where AI meets parental intuition** ğŸ¼âœ¨

*Helping exhausted parents understand their babies, one cry at a time.* 